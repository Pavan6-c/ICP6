{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pavan6-c/ICP6/blob/main/ICP6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqJvooAwOhGv",
        "outputId": "1dff3a95-023b-47bd-81ef-6a6eb90883ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.6848 - loss: 0.9350 - val_accuracy: 0.8298 - val_loss: 0.4872\n",
            "Epoch 2/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8505 - loss: 0.4153 - val_accuracy: 0.8668 - val_loss: 0.3758\n",
            "Epoch 3/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8712 - loss: 0.3555 - val_accuracy: 0.8792 - val_loss: 0.3427\n",
            "Epoch 4/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8850 - loss: 0.3158 - val_accuracy: 0.8742 - val_loss: 0.3450\n",
            "Epoch 5/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.8905 - loss: 0.2956 - val_accuracy: 0.8853 - val_loss: 0.3226\n",
            "Epoch 6/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.8918 - loss: 0.2923 - val_accuracy: 0.8805 - val_loss: 0.3397\n",
            "Epoch 7/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9002 - loss: 0.2678 - val_accuracy: 0.8873 - val_loss: 0.3181\n",
            "Epoch 8/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 10ms/step - accuracy: 0.9075 - loss: 0.2539 - val_accuracy: 0.8797 - val_loss: 0.3293\n",
            "Epoch 9/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.9097 - loss: 0.2449 - val_accuracy: 0.8883 - val_loss: 0.3151\n",
            "Epoch 10/10\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9126 - loss: 0.2354 - val_accuracy: 0.8872 - val_loss: 0.3250\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8805 - loss: 0.3306\n",
            "Test accuracy with Adam: 88.09%\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train_cat, epochs=10, batch_size=128, validation_split=0.1)\n",
        "\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test_cat)\n",
        "print(f'Test accuracy with Adam: {test_acc * 100:.2f}%')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='tanh'))        # changed activation to tanh\n",
        "model.add(Dense(16, activation='relu'))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])  # changed loss to categorical_crossentropy\n",
        "\n",
        "model.fit(x_train, y_train_cat, epochs=12, batch_size=128, validation_split=0.1)  # increased epochs\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test_cat)\n",
        "print(f'Test accuracy with SGD: {test_acc * 100:.2f}%')  # fixed print label from Adam to SGD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nb-3k2kHQOGX",
        "outputId": "ccce379e-e01d-42e7-fb36-637713279ba4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/12\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.5757 - loss: 1.1761 - val_accuracy: 0.8245 - val_loss: 0.4821\n",
            "Epoch 2/12\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.8424 - loss: 0.4414 - val_accuracy: 0.8517 - val_loss: 0.4049\n",
            "Epoch 3/12\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.8596 - loss: 0.3911 - val_accuracy: 0.8472 - val_loss: 0.4215\n",
            "Epoch 4/12\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.8678 - loss: 0.3624 - val_accuracy: 0.8675 - val_loss: 0.3590\n",
            "Epoch 5/12\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8776 - loss: 0.3347 - val_accuracy: 0.8642 - val_loss: 0.3592\n",
            "Epoch 6/12\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8843 - loss: 0.3156 - val_accuracy: 0.8725 - val_loss: 0.3453\n",
            "Epoch 7/12\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.8897 - loss: 0.3039 - val_accuracy: 0.8753 - val_loss: 0.3429\n",
            "Epoch 8/12\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.8951 - loss: 0.2836 - val_accuracy: 0.8763 - val_loss: 0.3341\n",
            "Epoch 9/12\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.8953 - loss: 0.2828 - val_accuracy: 0.8773 - val_loss: 0.3263\n",
            "Epoch 10/12\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - accuracy: 0.9036 - loss: 0.2652 - val_accuracy: 0.8835 - val_loss: 0.3280\n",
            "Epoch 11/12\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9060 - loss: 0.2541 - val_accuracy: 0.8847 - val_loss: 0.3145\n",
            "Epoch 12/12\n",
            "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - accuracy: 0.9070 - loss: 0.2470 - val_accuracy: 0.8785 - val_loss: 0.3348\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8712 - loss: 0.3710\n",
            "Test accuracy with SGD: 87.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "model.add(Dense(512, activation='sigmoid'))\n",
        "model.add(Dense(256, activation='sigmoid'))\n",
        "model.add(Dense(128, activation='relu'))         # changed activation to relu\n",
        "model.add(Dense(64, activation='sigmoid'))\n",
        "model.add(Dense(32, activation='relu'))          # changed activation to relu\n",
        "model.add(Dense(16, activation='sigmoid'))\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0006),  # added custom learning rate\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train_cat, epochs=12, batch_size=128, validation_split=0.2)  # increased epochs\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test_cat)\n",
        "print(f'Test accuracy: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CS12EPevO_hn",
        "outputId": "c419d264-bc3f-4cfd-ffeb-ab92831bdace"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 21ms/step - accuracy: 0.2912 - loss: 2.0331 - val_accuracy: 0.7368 - val_loss: 1.1753\n",
            "Epoch 2/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.7480 - loss: 1.0511 - val_accuracy: 0.8257 - val_loss: 0.7447\n",
            "Epoch 3/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.8533 - loss: 0.6807 - val_accuracy: 0.9078 - val_loss: 0.4925\n",
            "Epoch 4/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.9110 - loss: 0.4677 - val_accuracy: 0.9270 - val_loss: 0.3715\n",
            "Epoch 5/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.9286 - loss: 0.3544 - val_accuracy: 0.9402 - val_loss: 0.2938\n",
            "Epoch 6/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 19ms/step - accuracy: 0.9386 - loss: 0.2889 - val_accuracy: 0.9475 - val_loss: 0.2457\n",
            "Epoch 7/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.9511 - loss: 0.2300 - val_accuracy: 0.9547 - val_loss: 0.2122\n",
            "Epoch 8/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9583 - loss: 0.1956 - val_accuracy: 0.9532 - val_loss: 0.2035\n",
            "Epoch 9/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9634 - loss: 0.1669 - val_accuracy: 0.9578 - val_loss: 0.1788\n",
            "Epoch 10/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.9689 - loss: 0.1398 - val_accuracy: 0.9646 - val_loss: 0.1497\n",
            "Epoch 11/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 17ms/step - accuracy: 0.9715 - loss: 0.1251 - val_accuracy: 0.9663 - val_loss: 0.1427\n",
            "Epoch 12/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9754 - loss: 0.1082 - val_accuracy: 0.9653 - val_loss: 0.1406\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9555 - loss: 0.1716\n",
            "Test accuracy: 96.06%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST dataset (handwritten digits 0-9)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "# One-hot encode labels for 10 classes\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "# Add more Dense layers with sigmoid activation\n",
        "model.add(Dense(512, activation='tanh'))\n",
        "model.add(Dense(256, activation='tanh'))\n",
        "model.add(Dense(128, activation='relu'))       # changed activation to relu\n",
        "model.add(Dense(64, activation='tanh'))\n",
        "model.add(Dense(32, activation='relu'))        # changed activation to relu\n",
        "model.add(Dense(16, activation='tanh'))\n",
        "\n",
        "# Output layer with softmax for multiclass classification\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model with Adam optimizer and correct loss for multiclass\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0007),  # added custom learning rate\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train_cat, epochs=12, batch_size=128, validation_split=0.2)  # increased epochs\n",
        "\n",
        "# Evaluate on test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test_cat)\n",
        "print(f'Test accuracy: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyMJg6AoS2jK",
        "outputId": "3272cf3a-526f-4807-b537-7baf71c3a109"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.8022 - loss: 0.8605 - val_accuracy: 0.9507 - val_loss: 0.2183\n",
            "Epoch 2/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.9524 - loss: 0.1979 - val_accuracy: 0.9606 - val_loss: 0.1551\n",
            "Epoch 3/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9670 - loss: 0.1280 - val_accuracy: 0.9684 - val_loss: 0.1247\n",
            "Epoch 4/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 20ms/step - accuracy: 0.9754 - loss: 0.0919 - val_accuracy: 0.9693 - val_loss: 0.1164\n",
            "Epoch 5/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 18ms/step - accuracy: 0.9809 - loss: 0.0729 - val_accuracy: 0.9694 - val_loss: 0.1127\n",
            "Epoch 6/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9859 - loss: 0.0542 - val_accuracy: 0.9697 - val_loss: 0.1158\n",
            "Epoch 7/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 20ms/step - accuracy: 0.9869 - loss: 0.0477 - val_accuracy: 0.9729 - val_loss: 0.1059\n",
            "Epoch 8/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 19ms/step - accuracy: 0.9908 - loss: 0.0361 - val_accuracy: 0.9732 - val_loss: 0.1048\n",
            "Epoch 9/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - accuracy: 0.9904 - loss: 0.0349 - val_accuracy: 0.9733 - val_loss: 0.1024\n",
            "Epoch 10/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9933 - loss: 0.0266 - val_accuracy: 0.9601 - val_loss: 0.1568\n",
            "Epoch 11/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - accuracy: 0.9890 - loss: 0.0401 - val_accuracy: 0.9737 - val_loss: 0.1084\n",
            "Epoch 12/12\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.9934 - loss: 0.0225 - val_accuracy: 0.9732 - val_loss: 0.1078\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9677 - loss: 0.1169\n",
            "Test accuracy: 97.30%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Activation, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "for units in [512, 256, 128, 64, 32, 16]:\n",
        "    model.add(Dense(units))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.25))  # reduced dropout rate slightly\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0008),  # added custom learning rate\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)  # reduced patience\n",
        "\n",
        "model.fit(x_train, y_train_cat,\n",
        "          epochs=18,                   # increased epochs slightly\n",
        "          batch_size=128,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[early_stop])\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test_cat)\n",
        "print(f'Test accuracy: {test_acc * 100:.2f}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QfkSHpEmUs0o",
        "outputId": "8c406db6-83ca-4115-ef17-44dedc7bd809"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 28ms/step - accuracy: 0.4145 - loss: 1.7564 - val_accuracy: 0.9316 - val_loss: 0.3874\n",
            "Epoch 2/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 25ms/step - accuracy: 0.8289 - loss: 0.6651 - val_accuracy: 0.9544 - val_loss: 0.1864\n",
            "Epoch 3/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 21ms/step - accuracy: 0.8820 - loss: 0.4464 - val_accuracy: 0.9662 - val_loss: 0.1400\n",
            "Epoch 4/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9094 - loss: 0.3451 - val_accuracy: 0.9668 - val_loss: 0.1337\n",
            "Epoch 5/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9250 - loss: 0.2974 - val_accuracy: 0.9708 - val_loss: 0.1248\n",
            "Epoch 6/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - accuracy: 0.9323 - loss: 0.2649 - val_accuracy: 0.9714 - val_loss: 0.1155\n",
            "Epoch 7/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9355 - loss: 0.2451 - val_accuracy: 0.9714 - val_loss: 0.1161\n",
            "Epoch 8/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - accuracy: 0.9436 - loss: 0.2276 - val_accuracy: 0.9733 - val_loss: 0.1150\n",
            "Epoch 9/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 24ms/step - accuracy: 0.9490 - loss: 0.2004 - val_accuracy: 0.9741 - val_loss: 0.1180\n",
            "Epoch 10/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9489 - loss: 0.1919 - val_accuracy: 0.9758 - val_loss: 0.1016\n",
            "Epoch 11/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - accuracy: 0.9542 - loss: 0.1770 - val_accuracy: 0.9775 - val_loss: 0.1012\n",
            "Epoch 12/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9549 - loss: 0.1793 - val_accuracy: 0.9786 - val_loss: 0.1003\n",
            "Epoch 13/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - accuracy: 0.9546 - loss: 0.1773 - val_accuracy: 0.9772 - val_loss: 0.1075\n",
            "Epoch 14/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 23ms/step - accuracy: 0.9593 - loss: 0.1538 - val_accuracy: 0.9795 - val_loss: 0.0962\n",
            "Epoch 15/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 25ms/step - accuracy: 0.9622 - loss: 0.1445 - val_accuracy: 0.9793 - val_loss: 0.1034\n",
            "Epoch 16/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 26ms/step - accuracy: 0.9614 - loss: 0.1470 - val_accuracy: 0.9820 - val_loss: 0.0900\n",
            "Epoch 17/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - accuracy: 0.9643 - loss: 0.1361 - val_accuracy: 0.9807 - val_loss: 0.1033\n",
            "Epoch 18/18\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 22ms/step - accuracy: 0.9660 - loss: 0.1324 - val_accuracy: 0.9815 - val_loss: 0.0991\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9794 - loss: 0.0950\n",
            "Test accuracy: 98.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Load and preprocess data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "# Build model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "# Dense-only layers\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dense(512, activation='tanh'))        # changed activation to tanh\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(128, activation='tanh'))        # changed activation to tanh\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile with custom learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00065)  # slightly reduced learning rate\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "model.fit(x_train, y_train_cat,\n",
        "          epochs=6,                               # slightly increased epochs\n",
        "          batch_size=128,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[early_stop])\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test_cat)\n",
        "print(f'Test accuracy: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHt43GY6aa18",
        "outputId": "4c8b2eae-22e3-49f6-f909-0aef47b4c134"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 48ms/step - accuracy: 0.8139 - loss: 0.6089 - val_accuracy: 0.9616 - val_loss: 0.1265\n",
            "Epoch 2/6\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.9715 - loss: 0.0958 - val_accuracy: 0.9702 - val_loss: 0.1029\n",
            "Epoch 3/6\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 51ms/step - accuracy: 0.9797 - loss: 0.0650 - val_accuracy: 0.9704 - val_loss: 0.1021\n",
            "Epoch 4/6\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 46ms/step - accuracy: 0.9866 - loss: 0.0429 - val_accuracy: 0.9747 - val_loss: 0.0915\n",
            "Epoch 5/6\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 46ms/step - accuracy: 0.9879 - loss: 0.0378 - val_accuracy: 0.9728 - val_loss: 0.1003\n",
            "Epoch 6/6\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 44ms/step - accuracy: 0.9909 - loss: 0.0298 - val_accuracy: 0.9732 - val_loss: 0.1061\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9725 - loss: 0.0928\n",
            "Test accuracy: 97.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='tanh'))         # changed activation to tanh\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))          # added an extra hidden layer\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0009)  # slightly decreased learning rate\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=15,\n",
        "          batch_size=64,\n",
        "          validation_split=0.2)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-y-e8DhVAWx",
        "outputId": "1359d0c6-c26f-4482-b5b7-b9f677e962db"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 15ms/step - accuracy: 0.8739 - loss: 0.4257 - val_accuracy: 0.9587 - val_loss: 0.1366\n",
            "Epoch 2/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9708 - loss: 0.0958 - val_accuracy: 0.9654 - val_loss: 0.1151\n",
            "Epoch 3/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9803 - loss: 0.0616 - val_accuracy: 0.9734 - val_loss: 0.0900\n",
            "Epoch 4/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.9850 - loss: 0.0471 - val_accuracy: 0.9739 - val_loss: 0.0878\n",
            "Epoch 5/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 14ms/step - accuracy: 0.9875 - loss: 0.0370 - val_accuracy: 0.9775 - val_loss: 0.0824\n",
            "Epoch 6/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9895 - loss: 0.0316 - val_accuracy: 0.9748 - val_loss: 0.0979\n",
            "Epoch 7/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9907 - loss: 0.0270 - val_accuracy: 0.9757 - val_loss: 0.1000\n",
            "Epoch 8/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9921 - loss: 0.0257 - val_accuracy: 0.9737 - val_loss: 0.1105\n",
            "Epoch 9/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 15ms/step - accuracy: 0.9928 - loss: 0.0205 - val_accuracy: 0.9728 - val_loss: 0.1150\n",
            "Epoch 10/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.9935 - loss: 0.0203 - val_accuracy: 0.9750 - val_loss: 0.1052\n",
            "Epoch 11/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 15ms/step - accuracy: 0.9959 - loss: 0.0131 - val_accuracy: 0.9758 - val_loss: 0.1008\n",
            "Epoch 12/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 16ms/step - accuracy: 0.9947 - loss: 0.0148 - val_accuracy: 0.9767 - val_loss: 0.1096\n",
            "Epoch 13/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 14ms/step - accuracy: 0.9956 - loss: 0.0127 - val_accuracy: 0.9794 - val_loss: 0.0885\n",
            "Epoch 14/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 15ms/step - accuracy: 0.9964 - loss: 0.0101 - val_accuracy: 0.9737 - val_loss: 0.1192\n",
            "Epoch 15/15\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - accuracy: 0.9976 - loss: 0.0084 - val_accuracy: 0.9746 - val_loss: 0.1269\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9743 - loss: 0.1276\n",
            "Test accuracy: 97.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train_cat = to_categorical(y_train, 10)\n",
        "y_test_cat = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "model.add(Dense(1024, activation='tanh'))\n",
        "model.add(Dense(512, activation='relu'))       # changed activation to relu\n",
        "model.add(Dense(256, activation='tanh'))\n",
        "model.add(Dense(128, activation='relu'))       # changed activation to relu\n",
        "model.add(Dense(64, activation='tanh'))\n",
        "model.add(Dense(32, activation='relu'))        # changed activation to relu\n",
        "\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0006)  # slightly reduced learning rate\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "model.fit(x_train, y_train_cat,\n",
        "          epochs=6,                            # increased epochs slightly\n",
        "          batch_size=128,\n",
        "          validation_split=0.2,\n",
        "          callbacks=[early_stop])\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test_cat)\n",
        "print(f'Test accuracy: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C03DPaGNbkz-",
        "outputId": "470ce64f-3d70-451d-fdf9-9eeefa94d9c6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 48ms/step - accuracy: 0.8338 - loss: 0.5815 - val_accuracy: 0.9600 - val_loss: 0.1351\n",
            "Epoch 2/6\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - accuracy: 0.9664 - loss: 0.1145 - val_accuracy: 0.9663 - val_loss: 0.1103\n",
            "Epoch 3/6\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 46ms/step - accuracy: 0.9758 - loss: 0.0788 - val_accuracy: 0.9700 - val_loss: 0.1034\n",
            "Epoch 4/6\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 45ms/step - accuracy: 0.9812 - loss: 0.0604 - val_accuracy: 0.9717 - val_loss: 0.0999\n",
            "Epoch 5/6\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 49ms/step - accuracy: 0.9875 - loss: 0.0437 - val_accuracy: 0.9701 - val_loss: 0.1132\n",
            "Epoch 6/6\n",
            "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 46ms/step - accuracy: 0.9867 - loss: 0.0406 - val_accuracy: 0.9753 - val_loss: 0.0878\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9720 - loss: 0.0990\n",
            "Test accuracy: 97.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "model.add(Dense(256, activation='relu'))       # increased neurons\n",
        "model.add(Dense(64, activation='tanh'))         # added an extra hidden layer with tanh\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Custom optimizer with lower learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00045)  # slightly decreased learning rate\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train longer (more epochs)\n",
        "model.fit(x_train, y_train, epochs=25, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Evaluate\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "b5nNbA69oHz1",
        "outputId": "17e2175f-e6bb-4741-eb54-2d132d3dbea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8356 - loss: 0.6088 - val_accuracy: 0.9544 - val_loss: 0.1604\n",
            "Epoch 2/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9627 - loss: 0.1350 - val_accuracy: 0.9648 - val_loss: 0.1137\n",
            "Epoch 3/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9759 - loss: 0.0873 - val_accuracy: 0.9699 - val_loss: 0.0984\n",
            "Epoch 4/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.9825 - loss: 0.0611 - val_accuracy: 0.9709 - val_loss: 0.0904\n",
            "Epoch 5/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9876 - loss: 0.0466 - val_accuracy: 0.9764 - val_loss: 0.0792\n",
            "Epoch 6/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9917 - loss: 0.0319 - val_accuracy: 0.9780 - val_loss: 0.0788\n",
            "Epoch 7/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9944 - loss: 0.0221 - val_accuracy: 0.9774 - val_loss: 0.0783\n",
            "Epoch 8/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9955 - loss: 0.0173 - val_accuracy: 0.9761 - val_loss: 0.0807\n",
            "Epoch 9/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9964 - loss: 0.0138 - val_accuracy: 0.9773 - val_loss: 0.0782\n",
            "Epoch 10/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0087 - val_accuracy: 0.9792 - val_loss: 0.0755\n",
            "Epoch 11/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0059 - val_accuracy: 0.9769 - val_loss: 0.0857\n",
            "Epoch 12/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.9985 - loss: 0.0074 - val_accuracy: 0.9774 - val_loss: 0.0915\n",
            "Epoch 13/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9986 - loss: 0.0058 - val_accuracy: 0.9783 - val_loss: 0.0891\n",
            "Epoch 14/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9991 - loss: 0.0048 - val_accuracy: 0.9766 - val_loss: 0.0918\n",
            "Epoch 15/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - accuracy: 0.9991 - loss: 0.0043 - val_accuracy: 0.9775 - val_loss: 0.0963\n",
            "Epoch 16/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9981 - loss: 0.0072 - val_accuracy: 0.9791 - val_loss: 0.0836\n",
            "Epoch 17/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 0.9996 - loss: 0.0025 - val_accuracy: 0.9758 - val_loss: 0.1011\n",
            "Epoch 18/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 0.9780 - val_loss: 0.0966\n",
            "Epoch 19/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.9998 - loss: 0.0020 - val_accuracy: 0.9793 - val_loss: 0.0892\n",
            "Epoch 20/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - accuracy: 1.0000 - loss: 6.4375e-04 - val_accuracy: 0.9797 - val_loss: 0.0903\n",
            "Epoch 21/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 3.0724e-04 - val_accuracy: 0.9818 - val_loss: 0.0860\n",
            "Epoch 22/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 0.9971 - loss: 0.0078 - val_accuracy: 0.9776 - val_loss: 0.0994\n",
            "Epoch 23/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9994 - loss: 0.0028 - val_accuracy: 0.9789 - val_loss: 0.0964\n",
            "Epoch 24/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 9ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9797 - val_loss: 0.0917\n",
            "Epoch 25/25\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - accuracy: 1.0000 - loss: 2.4145e-04 - val_accuracy: 0.9812 - val_loss: 0.0895\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9780 - loss: 0.0937\n",
            "Test accuracy: 98.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='tanh'),         # changed activation to tanh\n",
        "    Dense(64, activation='relu'),          # added extra hidden layer\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with a smaller learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00035)  # slightly increased learning rate\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model (no callbacks)\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=25,                         # same number of epochs\n",
        "          batch_size=64,\n",
        "          validation_split=0.2,\n",
        "          verbose=2)\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'\\n✅ Test accuracy: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "77yy4bgNpLOH",
        "outputId": "137ae136-0f07-4a95-fda6-bf7c36109806",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "750/750 - 7s - 10ms/step - accuracy: 0.9054 - loss: 0.3542 - val_accuracy: 0.9492 - val_loss: 0.1709\n",
            "Epoch 2/25\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9615 - loss: 0.1307 - val_accuracy: 0.9646 - val_loss: 0.1182\n",
            "Epoch 3/25\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9738 - loss: 0.0874 - val_accuracy: 0.9690 - val_loss: 0.1041\n",
            "Epoch 4/25\n",
            "750/750 - 5s - 6ms/step - accuracy: 0.9812 - loss: 0.0616 - val_accuracy: 0.9727 - val_loss: 0.0900\n",
            "Epoch 5/25\n",
            "750/750 - 7s - 9ms/step - accuracy: 0.9868 - loss: 0.0452 - val_accuracy: 0.9726 - val_loss: 0.0937\n",
            "Epoch 6/25\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9899 - loss: 0.0346 - val_accuracy: 0.9699 - val_loss: 0.0987\n",
            "Epoch 7/25\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9926 - loss: 0.0253 - val_accuracy: 0.9739 - val_loss: 0.0933\n",
            "Epoch 8/25\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9937 - loss: 0.0210 - val_accuracy: 0.9763 - val_loss: 0.0885\n",
            "Epoch 9/25\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9955 - loss: 0.0155 - val_accuracy: 0.9775 - val_loss: 0.0874\n",
            "Epoch 10/25\n",
            "750/750 - 9s - 12ms/step - accuracy: 0.9972 - loss: 0.0108 - val_accuracy: 0.9758 - val_loss: 0.1023\n",
            "Epoch 11/25\n",
            "750/750 - 7s - 9ms/step - accuracy: 0.9958 - loss: 0.0125 - val_accuracy: 0.9728 - val_loss: 0.1088\n",
            "Epoch 12/25\n",
            "750/750 - 9s - 13ms/step - accuracy: 0.9967 - loss: 0.0109 - val_accuracy: 0.9756 - val_loss: 0.1081\n",
            "Epoch 13/25\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9975 - loss: 0.0084 - val_accuracy: 0.9762 - val_loss: 0.1080\n",
            "Epoch 14/25\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.9762 - val_loss: 0.1088\n",
            "Epoch 15/25\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9740 - val_loss: 0.1237\n",
            "Epoch 16/25\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9964 - loss: 0.0106 - val_accuracy: 0.9768 - val_loss: 0.1091\n",
            "Epoch 17/25\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9768 - val_loss: 0.1190\n",
            "Epoch 18/25\n",
            "750/750 - 6s - 7ms/step - accuracy: 0.9997 - loss: 0.0018 - val_accuracy: 0.9778 - val_loss: 0.1084\n",
            "Epoch 19/25\n",
            "750/750 - 7s - 9ms/step - accuracy: 0.9966 - loss: 0.0098 - val_accuracy: 0.9747 - val_loss: 0.1278\n",
            "Epoch 20/25\n",
            "750/750 - 9s - 11ms/step - accuracy: 0.9985 - loss: 0.0043 - val_accuracy: 0.9725 - val_loss: 0.1456\n",
            "Epoch 21/25\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9983 - loss: 0.0052 - val_accuracy: 0.9772 - val_loss: 0.1196\n",
            "Epoch 22/25\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9983 - loss: 0.0053 - val_accuracy: 0.9741 - val_loss: 0.1428\n",
            "Epoch 23/25\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9759 - val_loss: 0.1314\n",
            "Epoch 24/25\n",
            "750/750 - 6s - 9ms/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.9760 - val_loss: 0.1307\n",
            "Epoch 25/25\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9980 - loss: 0.0055 - val_accuracy: 0.9762 - val_loss: 0.1305\n",
            "\n",
            "✅ Test accuracy: 97.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dense(128, activation='tanh'),         # changed activation from relu to tanh\n",
        "    Dense(64, activation='relu'),          # added a new hidden layer\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00035)  # slightly increased learning rate\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=40,\n",
        "          batch_size=64,\n",
        "          validation_split=0.2,\n",
        "          verbose=2)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'\\nTest accuracy: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "gThVFzFurJwk",
        "outputId": "f234459f-4f6b-41ee-e5c4-7df40d275fd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "750/750 - 8s - 10ms/step - accuracy: 0.9050 - loss: 0.3429 - val_accuracy: 0.9575 - val_loss: 0.1478\n",
            "Epoch 2/40\n",
            "750/750 - 13s - 17ms/step - accuracy: 0.9626 - loss: 0.1263 - val_accuracy: 0.9660 - val_loss: 0.1174\n",
            "Epoch 3/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 0.9744 - loss: 0.0852 - val_accuracy: 0.9708 - val_loss: 0.0957\n",
            "Epoch 4/40\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9818 - loss: 0.0611 - val_accuracy: 0.9691 - val_loss: 0.1000\n",
            "Epoch 5/40\n",
            "750/750 - 7s - 9ms/step - accuracy: 0.9866 - loss: 0.0448 - val_accuracy: 0.9739 - val_loss: 0.0884\n",
            "Epoch 6/40\n",
            "750/750 - 8s - 11ms/step - accuracy: 0.9901 - loss: 0.0341 - val_accuracy: 0.9763 - val_loss: 0.0831\n",
            "Epoch 7/40\n",
            "750/750 - 6s - 9ms/step - accuracy: 0.9930 - loss: 0.0250 - val_accuracy: 0.9769 - val_loss: 0.0868\n",
            "Epoch 8/40\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9942 - loss: 0.0196 - val_accuracy: 0.9753 - val_loss: 0.0911\n",
            "Epoch 9/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9953 - loss: 0.0162 - val_accuracy: 0.9776 - val_loss: 0.0867\n",
            "Epoch 10/40\n",
            "750/750 - 7s - 9ms/step - accuracy: 0.9965 - loss: 0.0122 - val_accuracy: 0.9761 - val_loss: 0.0923\n",
            "Epoch 11/40\n",
            "750/750 - 8s - 11ms/step - accuracy: 0.9967 - loss: 0.0110 - val_accuracy: 0.9713 - val_loss: 0.1180\n",
            "Epoch 12/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9970 - loss: 0.0104 - val_accuracy: 0.9778 - val_loss: 0.0957\n",
            "Epoch 13/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9969 - loss: 0.0099 - val_accuracy: 0.9776 - val_loss: 0.0962\n",
            "Epoch 14/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.9783 - val_loss: 0.0938\n",
            "Epoch 15/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.9736 - val_loss: 0.1270\n",
            "Epoch 16/40\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9963 - loss: 0.0108 - val_accuracy: 0.9783 - val_loss: 0.1008\n",
            "Epoch 17/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9988 - loss: 0.0046 - val_accuracy: 0.9764 - val_loss: 0.1133\n",
            "Epoch 18/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9975 - loss: 0.0070 - val_accuracy: 0.9778 - val_loss: 0.1149\n",
            "Epoch 19/40\n",
            "750/750 - 8s - 10ms/step - accuracy: 0.9991 - loss: 0.0036 - val_accuracy: 0.9732 - val_loss: 0.1289\n",
            "Epoch 20/40\n",
            "750/750 - 8s - 10ms/step - accuracy: 0.9977 - loss: 0.0065 - val_accuracy: 0.9764 - val_loss: 0.1122\n",
            "Epoch 21/40\n",
            "750/750 - 7s - 9ms/step - accuracy: 0.9987 - loss: 0.0043 - val_accuracy: 0.9757 - val_loss: 0.1257\n",
            "Epoch 22/40\n",
            "750/750 - 6s - 7ms/step - accuracy: 0.9989 - loss: 0.0039 - val_accuracy: 0.9807 - val_loss: 0.1029\n",
            "Epoch 23/40\n",
            "750/750 - 7s - 9ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9767 - val_loss: 0.1321\n",
            "Epoch 24/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 0.9976 - loss: 0.0072 - val_accuracy: 0.9770 - val_loss: 0.1216\n",
            "Epoch 25/40\n",
            "750/750 - 7s - 9ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9776 - val_loss: 0.1270\n",
            "Epoch 26/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9728 - val_loss: 0.1556\n",
            "Epoch 27/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 0.9976 - loss: 0.0070 - val_accuracy: 0.9789 - val_loss: 0.1306\n",
            "Epoch 28/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.9798 - val_loss: 0.1149\n",
            "Epoch 29/40\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9790 - val_loss: 0.1283\n",
            "Epoch 30/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.9781 - val_loss: 0.1332\n",
            "Epoch 31/40\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9778 - val_loss: 0.1463\n",
            "Epoch 32/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9718 - val_loss: 0.1644\n",
            "Epoch 33/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9985 - loss: 0.0043 - val_accuracy: 0.9769 - val_loss: 0.1460\n",
            "Epoch 34/40\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9996 - loss: 0.0012 - val_accuracy: 0.9820 - val_loss: 0.1212\n",
            "Epoch 35/40\n",
            "750/750 - 6s - 9ms/step - accuracy: 0.9999 - loss: 6.2871e-04 - val_accuracy: 0.9818 - val_loss: 0.1193\n",
            "Epoch 36/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 1.0000 - loss: 6.2326e-05 - val_accuracy: 0.9821 - val_loss: 0.1189\n",
            "Epoch 37/40\n",
            "750/750 - 8s - 11ms/step - accuracy: 1.0000 - loss: 2.8907e-05 - val_accuracy: 0.9822 - val_loss: 0.1190\n",
            "Epoch 38/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 1.0000 - loss: 2.2432e-05 - val_accuracy: 0.9821 - val_loss: 0.1195\n",
            "Epoch 39/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 1.0000 - loss: 1.7955e-05 - val_accuracy: 0.9820 - val_loss: 0.1202\n",
            "Epoch 40/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 1.0000 - loss: 1.4347e-05 - val_accuracy: 0.9818 - val_loss: 0.1209\n",
            "\n",
            "Test accuracy: 98.21%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build the model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='tanh'),      # changed activation from relu to tanh\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(64, activation='relu'),       # added an extra hidden layer\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model with a smaller learning rate\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00035)  # slightly increased learning rate\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model (no callbacks)\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=40,\n",
        "          batch_size=64,\n",
        "          validation_split=0.2,\n",
        "          verbose=2)\n",
        "\n",
        "# Evaluate on test set\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'\\n Test accuracy: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "-c3FbIvjuzrE",
        "outputId": "6f50194f-e909-45b8-cb25-457064d8aacb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "750/750 - 8s - 11ms/step - accuracy: 0.8959 - loss: 0.3723 - val_accuracy: 0.9454 - val_loss: 0.1882\n",
            "Epoch 2/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 0.9527 - loss: 0.1579 - val_accuracy: 0.9576 - val_loss: 0.1419\n",
            "Epoch 3/40\n",
            "750/750 - 7s - 10ms/step - accuracy: 0.9653 - loss: 0.1142 - val_accuracy: 0.9645 - val_loss: 0.1199\n",
            "Epoch 4/40\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9737 - loss: 0.0880 - val_accuracy: 0.9683 - val_loss: 0.1081\n",
            "Epoch 5/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9800 - loss: 0.0693 - val_accuracy: 0.9713 - val_loss: 0.0972\n",
            "Epoch 6/40\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9827 - loss: 0.0567 - val_accuracy: 0.9722 - val_loss: 0.0918\n",
            "Epoch 7/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9868 - loss: 0.0444 - val_accuracy: 0.9738 - val_loss: 0.0912\n",
            "Epoch 8/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 0.9890 - loss: 0.0368 - val_accuracy: 0.9697 - val_loss: 0.1037\n",
            "Epoch 9/40\n",
            "750/750 - 6s - 7ms/step - accuracy: 0.9908 - loss: 0.0299 - val_accuracy: 0.9747 - val_loss: 0.0915\n",
            "Epoch 10/40\n",
            "750/750 - 8s - 10ms/step - accuracy: 0.9930 - loss: 0.0243 - val_accuracy: 0.9730 - val_loss: 0.0923\n",
            "Epoch 11/40\n",
            "750/750 - 8s - 11ms/step - accuracy: 0.9942 - loss: 0.0196 - val_accuracy: 0.9741 - val_loss: 0.0932\n",
            "Epoch 12/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9950 - loss: 0.0170 - val_accuracy: 0.9739 - val_loss: 0.1029\n",
            "Epoch 13/40\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9963 - loss: 0.0132 - val_accuracy: 0.9757 - val_loss: 0.0958\n",
            "Epoch 14/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9971 - loss: 0.0107 - val_accuracy: 0.9738 - val_loss: 0.1069\n",
            "Epoch 15/40\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9967 - loss: 0.0111 - val_accuracy: 0.9750 - val_loss: 0.1048\n",
            "Epoch 16/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9971 - loss: 0.0094 - val_accuracy: 0.9758 - val_loss: 0.1007\n",
            "Epoch 17/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9976 - loss: 0.0083 - val_accuracy: 0.9753 - val_loss: 0.1045\n",
            "Epoch 18/40\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9982 - loss: 0.0067 - val_accuracy: 0.9742 - val_loss: 0.1133\n",
            "Epoch 19/40\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9979 - loss: 0.0077 - val_accuracy: 0.9743 - val_loss: 0.1158\n",
            "Epoch 20/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.9793 - val_loss: 0.0992\n",
            "Epoch 21/40\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9978 - loss: 0.0065 - val_accuracy: 0.9770 - val_loss: 0.1105\n",
            "Epoch 22/40\n",
            "750/750 - 8s - 11ms/step - accuracy: 0.9984 - loss: 0.0054 - val_accuracy: 0.9744 - val_loss: 0.1255\n",
            "Epoch 23/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 0.9788 - val_loss: 0.1100\n",
            "Epoch 24/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9980 - loss: 0.0060 - val_accuracy: 0.9755 - val_loss: 0.1188\n",
            "Epoch 25/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 0.9979 - loss: 0.0065 - val_accuracy: 0.9737 - val_loss: 0.1312\n",
            "Epoch 26/40\n",
            "750/750 - 6s - 7ms/step - accuracy: 0.9985 - loss: 0.0043 - val_accuracy: 0.9793 - val_loss: 0.1071\n",
            "Epoch 27/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 1.0000 - loss: 4.3748e-04 - val_accuracy: 0.9803 - val_loss: 0.1051\n",
            "Epoch 28/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 1.0000 - loss: 2.0799e-04 - val_accuracy: 0.9804 - val_loss: 0.1047\n",
            "Epoch 29/40\n",
            "750/750 - 7s - 9ms/step - accuracy: 1.0000 - loss: 1.5774e-04 - val_accuracy: 0.9795 - val_loss: 0.1078\n",
            "Epoch 30/40\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9985 - loss: 0.0053 - val_accuracy: 0.9663 - val_loss: 0.1867\n",
            "Epoch 31/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9958 - loss: 0.0133 - val_accuracy: 0.9788 - val_loss: 0.1112\n",
            "Epoch 32/40\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9793 - val_loss: 0.1098\n",
            "Epoch 33/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 1.0000 - loss: 2.3460e-04 - val_accuracy: 0.9799 - val_loss: 0.1101\n",
            "Epoch 34/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 1.0000 - loss: 1.4553e-04 - val_accuracy: 0.9801 - val_loss: 0.1108\n",
            "Epoch 35/40\n",
            "750/750 - 7s - 9ms/step - accuracy: 1.0000 - loss: 1.1248e-04 - val_accuracy: 0.9803 - val_loss: 0.1111\n",
            "Epoch 36/40\n",
            "750/750 - 5s - 7ms/step - accuracy: 1.0000 - loss: 8.4451e-05 - val_accuracy: 0.9800 - val_loss: 0.1140\n",
            "Epoch 37/40\n",
            "750/750 - 6s - 8ms/step - accuracy: 1.0000 - loss: 7.3548e-05 - val_accuracy: 0.9799 - val_loss: 0.1164\n",
            "Epoch 38/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 1.0000 - loss: 5.7206e-05 - val_accuracy: 0.9792 - val_loss: 0.1186\n",
            "Epoch 39/40\n",
            "750/750 - 6s - 9ms/step - accuracy: 0.9973 - loss: 0.0120 - val_accuracy: 0.9656 - val_loss: 0.1949\n",
            "Epoch 40/40\n",
            "750/750 - 5s - 7ms/step - accuracy: 0.9971 - loss: 0.0095 - val_accuracy: 0.9771 - val_loss: 0.1231\n",
            "\n",
            " Test accuracy: 97.93%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='tanh'),       # changed activation function\n",
        "    Dense(128, activation='relu'),       # added extra hidden layer\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)   # slight learning rate increase\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=40,\n",
        "          batch_size=64,\n",
        "          validation_split=0.2,\n",
        "          verbose=2)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'\\nTest accuracy: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "aIqCvNNwwzp0",
        "outputId": "ba41d2fb-5aeb-4a24-8f91-dfce01787dbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "750/750 - 12s - 16ms/step - accuracy: 0.9275 - loss: 0.2476 - val_accuracy: 0.9607 - val_loss: 0.1285\n",
            "Epoch 2/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9711 - loss: 0.0939 - val_accuracy: 0.9655 - val_loss: 0.1114\n",
            "Epoch 3/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 0.9816 - loss: 0.0592 - val_accuracy: 0.9713 - val_loss: 0.0974\n",
            "Epoch 4/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 0.9866 - loss: 0.0409 - val_accuracy: 0.9736 - val_loss: 0.0918\n",
            "Epoch 5/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9901 - loss: 0.0296 - val_accuracy: 0.9734 - val_loss: 0.0942\n",
            "Epoch 6/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 0.9912 - loss: 0.0267 - val_accuracy: 0.9742 - val_loss: 0.0959\n",
            "Epoch 7/40\n",
            "750/750 - 19s - 25ms/step - accuracy: 0.9934 - loss: 0.0194 - val_accuracy: 0.9737 - val_loss: 0.1102\n",
            "Epoch 8/40\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9946 - loss: 0.0160 - val_accuracy: 0.9798 - val_loss: 0.0835\n",
            "Epoch 9/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 0.9941 - loss: 0.0175 - val_accuracy: 0.9741 - val_loss: 0.1069\n",
            "Epoch 10/40\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9960 - loss: 0.0119 - val_accuracy: 0.9780 - val_loss: 0.1031\n",
            "Epoch 11/40\n",
            "750/750 - 21s - 28ms/step - accuracy: 0.9962 - loss: 0.0110 - val_accuracy: 0.9779 - val_loss: 0.1107\n",
            "Epoch 12/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 0.9955 - loss: 0.0137 - val_accuracy: 0.9766 - val_loss: 0.1118\n",
            "Epoch 13/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9962 - loss: 0.0112 - val_accuracy: 0.9807 - val_loss: 0.0956\n",
            "Epoch 14/40\n",
            "750/750 - 12s - 16ms/step - accuracy: 0.9967 - loss: 0.0092 - val_accuracy: 0.9784 - val_loss: 0.1162\n",
            "Epoch 15/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9967 - loss: 0.0094 - val_accuracy: 0.9773 - val_loss: 0.1194\n",
            "Epoch 16/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 0.9977 - loss: 0.0066 - val_accuracy: 0.9801 - val_loss: 0.1061\n",
            "Epoch 17/40\n",
            "750/750 - 20s - 26ms/step - accuracy: 0.9967 - loss: 0.0103 - val_accuracy: 0.9788 - val_loss: 0.1156\n",
            "Epoch 18/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9984 - loss: 0.0048 - val_accuracy: 0.9758 - val_loss: 0.1378\n",
            "Epoch 19/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9971 - loss: 0.0087 - val_accuracy: 0.9781 - val_loss: 0.1206\n",
            "Epoch 20/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 0.9972 - loss: 0.0087 - val_accuracy: 0.9816 - val_loss: 0.1062\n",
            "Epoch 21/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9986 - loss: 0.0046 - val_accuracy: 0.9779 - val_loss: 0.1252\n",
            "Epoch 22/40\n",
            "750/750 - 12s - 15ms/step - accuracy: 0.9966 - loss: 0.0103 - val_accuracy: 0.9772 - val_loss: 0.1241\n",
            "Epoch 23/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9974 - loss: 0.0069 - val_accuracy: 0.9749 - val_loss: 0.1502\n",
            "Epoch 24/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9982 - loss: 0.0050 - val_accuracy: 0.9740 - val_loss: 0.1727\n",
            "Epoch 25/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9984 - loss: 0.0061 - val_accuracy: 0.9814 - val_loss: 0.1158\n",
            "Epoch 26/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9801 - val_loss: 0.1220\n",
            "Epoch 27/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.9715 - val_loss: 0.1575\n",
            "Epoch 28/40\n",
            "750/750 - 21s - 28ms/step - accuracy: 0.9980 - loss: 0.0066 - val_accuracy: 0.9754 - val_loss: 0.1499\n",
            "Epoch 29/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 0.9983 - loss: 0.0051 - val_accuracy: 0.9804 - val_loss: 0.1242\n",
            "Epoch 30/40\n",
            "750/750 - 9s - 13ms/step - accuracy: 0.9982 - loss: 0.0054 - val_accuracy: 0.9783 - val_loss: 0.1405\n",
            "Epoch 31/40\n",
            "750/750 - 12s - 16ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.9795 - val_loss: 0.1288\n",
            "Epoch 32/40\n",
            "750/750 - 18s - 25ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.9816 - val_loss: 0.1159\n",
            "Epoch 33/40\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9984 - loss: 0.0050 - val_accuracy: 0.9768 - val_loss: 0.1535\n",
            "Epoch 34/40\n",
            "750/750 - 20s - 27ms/step - accuracy: 0.9983 - loss: 0.0053 - val_accuracy: 0.9797 - val_loss: 0.1246\n",
            "Epoch 35/40\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.9808 - val_loss: 0.1185\n",
            "Epoch 36/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9783 - val_loss: 0.1378\n",
            "Epoch 37/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 0.9983 - loss: 0.0064 - val_accuracy: 0.9792 - val_loss: 0.1216\n",
            "Epoch 38/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9990 - loss: 0.0031 - val_accuracy: 0.9799 - val_loss: 0.1262\n",
            "Epoch 39/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 0.9819 - val_loss: 0.1251\n",
            "Epoch 40/40\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.9790 - val_loss: 0.1435\n",
            "\n",
            "Test accuracy: 98.10%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='tanh'),     # changed activation\n",
        "    Dense(128, activation='relu'),     # added new layer\n",
        "    Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0005)  # slightly increased lr\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          epochs=40,\n",
        "          batch_size=64,\n",
        "          validation_split=0.2,\n",
        "          verbose=2)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(f'\\nTest accuracy: {test_acc * 100:.2f}%')"
      ],
      "metadata": {
        "id": "M_G35LEV7Ujx",
        "outputId": "960862e7-a27d-4da6-df63-67a46f1b271c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "750/750 - 13s - 18ms/step - accuracy: 0.9266 - loss: 0.2455 - val_accuracy: 0.9611 - val_loss: 0.1278\n",
            "Epoch 2/40\n",
            "750/750 - 12s - 16ms/step - accuracy: 0.9728 - loss: 0.0896 - val_accuracy: 0.9721 - val_loss: 0.0918\n",
            "Epoch 3/40\n",
            "750/750 - 12s - 15ms/step - accuracy: 0.9818 - loss: 0.0565 - val_accuracy: 0.9707 - val_loss: 0.0996\n",
            "Epoch 4/40\n",
            "750/750 - 19s - 26ms/step - accuracy: 0.9873 - loss: 0.0410 - val_accuracy: 0.9700 - val_loss: 0.1125\n",
            "Epoch 5/40\n",
            "750/750 - 20s - 27ms/step - accuracy: 0.9900 - loss: 0.0310 - val_accuracy: 0.9753 - val_loss: 0.0934\n",
            "Epoch 6/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9916 - loss: 0.0246 - val_accuracy: 0.9743 - val_loss: 0.0953\n",
            "Epoch 7/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9935 - loss: 0.0194 - val_accuracy: 0.9768 - val_loss: 0.0957\n",
            "Epoch 8/40\n",
            "750/750 - 12s - 16ms/step - accuracy: 0.9936 - loss: 0.0187 - val_accuracy: 0.9750 - val_loss: 0.1095\n",
            "Epoch 9/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9937 - loss: 0.0187 - val_accuracy: 0.9785 - val_loss: 0.0941\n",
            "Epoch 10/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9968 - loss: 0.0105 - val_accuracy: 0.9732 - val_loss: 0.1259\n",
            "Epoch 11/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 0.9954 - loss: 0.0140 - val_accuracy: 0.9767 - val_loss: 0.1114\n",
            "Epoch 12/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 0.9750 - val_loss: 0.1151\n",
            "Epoch 13/40\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9964 - loss: 0.0101 - val_accuracy: 0.9757 - val_loss: 0.1263\n",
            "Epoch 14/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 0.9969 - loss: 0.0092 - val_accuracy: 0.9754 - val_loss: 0.1304\n",
            "Epoch 15/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 0.9963 - loss: 0.0117 - val_accuracy: 0.9759 - val_loss: 0.1273\n",
            "Epoch 16/40\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.9775 - val_loss: 0.1242\n",
            "Epoch 17/40\n",
            "750/750 - 19s - 26ms/step - accuracy: 0.9967 - loss: 0.0112 - val_accuracy: 0.9743 - val_loss: 0.1344\n",
            "Epoch 18/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.9785 - val_loss: 0.1164\n",
            "Epoch 19/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.9751 - val_loss: 0.1502\n",
            "Epoch 20/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 0.9971 - loss: 0.0087 - val_accuracy: 0.9802 - val_loss: 0.1181\n",
            "Epoch 21/40\n",
            "750/750 - 20s - 26ms/step - accuracy: 0.9973 - loss: 0.0083 - val_accuracy: 0.9766 - val_loss: 0.1295\n",
            "Epoch 22/40\n",
            "750/750 - 20s - 27ms/step - accuracy: 0.9976 - loss: 0.0069 - val_accuracy: 0.9772 - val_loss: 0.1331\n",
            "Epoch 23/40\n",
            "750/750 - 20s - 27ms/step - accuracy: 0.9981 - loss: 0.0051 - val_accuracy: 0.9748 - val_loss: 0.1382\n",
            "Epoch 24/40\n",
            "750/750 - 13s - 18ms/step - accuracy: 0.9984 - loss: 0.0045 - val_accuracy: 0.9796 - val_loss: 0.1220\n",
            "Epoch 25/40\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.9768 - val_loss: 0.1457\n",
            "Epoch 26/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9972 - loss: 0.0088 - val_accuracy: 0.9780 - val_loss: 0.1361\n",
            "Epoch 27/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9803 - val_loss: 0.1251\n",
            "Epoch 28/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 0.9973 - loss: 0.0087 - val_accuracy: 0.9796 - val_loss: 0.1233\n",
            "Epoch 29/40\n",
            "750/750 - 20s - 27ms/step - accuracy: 0.9975 - loss: 0.0083 - val_accuracy: 0.9786 - val_loss: 0.1362\n",
            "Epoch 30/40\n",
            "750/750 - 9s - 12ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9791 - val_loss: 0.1342\n",
            "Epoch 31/40\n",
            "750/750 - 11s - 14ms/step - accuracy: 0.9989 - loss: 0.0034 - val_accuracy: 0.9793 - val_loss: 0.1397\n",
            "Epoch 32/40\n",
            "750/750 - 10s - 14ms/step - accuracy: 0.9987 - loss: 0.0041 - val_accuracy: 0.9778 - val_loss: 0.1535\n",
            "Epoch 33/40\n",
            "750/750 - 11s - 15ms/step - accuracy: 0.9977 - loss: 0.0070 - val_accuracy: 0.9788 - val_loss: 0.1451\n",
            "Epoch 34/40\n",
            "750/750 - 19s - 26ms/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 0.9774 - val_loss: 0.1391\n",
            "Epoch 35/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9981 - loss: 0.0052 - val_accuracy: 0.9785 - val_loss: 0.1437\n",
            "Epoch 36/40\n",
            "750/750 - 12s - 16ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9783 - val_loss: 0.1415\n",
            "Epoch 37/40\n",
            "750/750 - 19s - 25ms/step - accuracy: 0.9974 - loss: 0.0076 - val_accuracy: 0.9795 - val_loss: 0.1304\n",
            "Epoch 38/40\n",
            "750/750 - 10s - 13ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9811 - val_loss: 0.1222\n",
            "Epoch 39/40\n",
            "750/750 - 12s - 16ms/step - accuracy: 0.9995 - loss: 0.0023 - val_accuracy: 0.9781 - val_loss: 0.1442\n",
            "Epoch 40/40\n",
            "750/750 - 18s - 24ms/step - accuracy: 0.9978 - loss: 0.0072 - val_accuracy: 0.9796 - val_loss: 0.1413\n",
            "\n",
            "Test accuracy: 98.11%\n"
          ]
        }
      ]
    }
  ]
}